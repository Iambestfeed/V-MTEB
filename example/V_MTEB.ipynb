{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nhan-softzone/V-MTEB\n"
     ]
    }
   ],
   "source": [
    "%cd /home/nhan-softzone/V-MTEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting transformers==4.39.1\n",
      "  Downloading transformers-4.39.1-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from transformers==4.39.1) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers==4.39.1)\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from transformers==4.39.1) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from transformers==4.39.1) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from transformers==4.39.1) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/nhan-softzone/.local/lib/python3.10/site-packages (from transformers==4.39.1) (2023.12.25)\n",
      "Requirement already satisfied: requests in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from transformers==4.39.1) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from transformers==4.39.1) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from transformers==4.39.1) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from transformers==4.39.1) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.1) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.1) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.1) (1.1.3)\n",
      "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.39.1)\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from requests->transformers==4.39.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from requests->transformers==4.39.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from requests->transformers==4.39.1) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from requests->transformers==4.39.1) (2023.11.17)\n",
      "Downloading transformers-4.39.1-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.8/514.8 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.17.3\n",
      "    Uninstalling huggingface-hub-0.17.3:\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.14.1\n",
      "    Uninstalling tokenizers-0.14.1:\n",
      "      Successfully uninstalled tokenizers-0.14.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.35.1\n",
      "    Uninstalling transformers-4.35.1:\n",
      "      Successfully uninstalled transformers-4.35.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 0.4.22 requires fastapi>=0.95.2, which is not installed.\n",
      "chromadb 0.4.22 requires importlib-resources, which is not installed.\n",
      "chromadb 0.4.22 requires opentelemetry-api>=1.2.0, which is not installed.\n",
      "chromadb 0.4.22 requires opentelemetry-exporter-otlp-proto-grpc>=1.2.0, which is not installed.\n",
      "chromadb 0.4.22 requires opentelemetry-sdk>=1.2.0, which is not installed.\n",
      "chromadb 0.4.22 requires typer>=0.9.0, which is not installed.\n",
      "gradio 4.16.0 requires fastapi, which is not installed.\n",
      "gradio 4.16.0 requires importlib-resources<7.0,>=1.3, which is not installed.\n",
      "gradio 4.16.0 requires typer[all]<1.0,>=0.9, which is not installed.\n",
      "salesforce-lavis 1.0.2 requires timm==0.4.12, but you have timm 1.0.3 which is incompatible.\n",
      "salesforce-lavis 1.0.2 requires transformers<4.27,>=4.25.0, but you have transformers 4.39.1 which is incompatible.\n",
      "text-dedup 0.4.0 requires numpy>=1.26.4, but you have numpy 1.26.3 which is incompatible.\n",
      "text-dedup 0.4.0 requires setuptools>=69.1.0, but you have setuptools 68.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.33.0 tokenizers-0.15.2 transformers-4.39.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.39.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting sentence_transformers==2.3.1\n",
      "  Downloading sentence_transformers-2.3.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from sentence_transformers==2.3.1) (4.35.1)\n",
      "Requirement already satisfied: tqdm in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from sentence_transformers==2.3.1) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from sentence_transformers==2.3.1) (2.0.1+cu117)\n",
      "Requirement already satisfied: numpy in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from sentence_transformers==2.3.1) (1.26.3)\n",
      "Requirement already satisfied: scikit-learn in /home/nhan-softzone/.local/lib/python3.10/site-packages (from sentence_transformers==2.3.1) (1.2.2)\n",
      "Requirement already satisfied: scipy in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from sentence_transformers==2.3.1) (1.15.2)\n",
      "Requirement already satisfied: nltk in /home/nhan-softzone/.local/lib/python3.10/site-packages (from sentence_transformers==2.3.1) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /home/nhan-softzone/.local/lib/python3.10/site-packages (from sentence_transformers==2.3.1) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from sentence_transformers==2.3.1) (0.17.3)\n",
      "Requirement already satisfied: Pillow in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from sentence_transformers==2.3.1) (10.2.0)\n",
      "Requirement already satisfied: filelock in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.3.1) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.3.1) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.3.1) (2.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.3.1) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.3.1) (4.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers==2.3.1) (23.2)\n",
      "Requirement already satisfied: sympy in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers==2.3.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers==2.3.1) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers==2.3.1) (3.1.4)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers==2.3.1) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11.0->sentence_transformers==2.3.1) (3.25.0)\n",
      "Requirement already satisfied: lit in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.11.0->sentence_transformers==2.3.1) (15.0.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/nhan-softzone/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers==2.3.1) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers==2.3.1) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers==2.3.1) (0.5.3)\n",
      "Requirement already satisfied: click in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from nltk->sentence_transformers==2.3.1) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/nhan-softzone/.local/lib/python3.10/site-packages (from nltk->sentence_transformers==2.3.1) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/nhan-softzone/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.3.1) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers==2.3.1) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers==2.3.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers==2.3.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers==2.3.1) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers==2.3.1) (2023.11.17)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers==2.3.1) (1.3.0)\n",
      "Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence_transformers\n",
      "  Attempting uninstall: sentence_transformers\n",
      "    Found existing installation: sentence-transformers 2.6.1\n",
      "    Uninstalling sentence-transformers-2.6.1:\n",
      "      Successfully uninstalled sentence-transformers-2.6.1\n",
      "Successfully installed sentence_transformers-2.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers==2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from V_MTEB import *\n",
    "from mteb import MTEB\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['vinai/phobert-base-v2',  \\n          'iambestfeed/phobert-base-v2-finetuned-raw_data_wseg-lr2e-05-1-epochs-bs-64',\\n          'iambestfeed/phobert-base-v2-finetuned-wiki-data-raw_data_wseg-lr2e-05-1-epochs-bs-48',\\n          'iambestfeed/phobert-base-v2-Vietnamese-Ecommerce-Alpaca-raw_data_wseg-lr2e-05-1-epochs-bs-48',\\n          'iambestfeed/phobert-base-v2-finetuneed-wiki-finetuned-vnexpress-data-similarity-lr2e-05-1-epochs-bs-48',\\n          'iambestfeed/phobert-base-v2-finetuneed-vnexpress-finetuned-wiki-data-raw_data_wseg-lr2e-05-1-epochs-bs-48',\\n          'iambestfeed/phobert-base-v2-vne_wiki_pair_data-raw_data_wseg-lr2e-05-1-epochs-bs-48',\\n          'iambestfeed/phobert-base-v2-vne-finetune-Ecommerce-raw_data_wseg-lr2e-05-1-epochs-bs-48',\\n          'iambestfeed/phobert-base-v2-ft-eco-vnexpress-data-similarity-raw_data_wseg-lr2e-05-1-epochs-bs-64']\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['iambestfeed/phobert_v2_flax_wiki_32_1e_2e5']\n",
    "'''['vinai/phobert-base-v2',  \n",
    "          'iambestfeed/phobert-base-v2-finetuned-raw_data_wseg-lr2e-05-1-epochs-bs-64',\n",
    "          'iambestfeed/phobert-base-v2-finetuned-wiki-data-raw_data_wseg-lr2e-05-1-epochs-bs-48',\n",
    "          'iambestfeed/phobert-base-v2-Vietnamese-Ecommerce-Alpaca-raw_data_wseg-lr2e-05-1-epochs-bs-48',\n",
    "          'iambestfeed/phobert-base-v2-finetuneed-wiki-finetuned-vnexpress-data-similarity-lr2e-05-1-epochs-bs-48',\n",
    "          'iambestfeed/phobert-base-v2-finetuneed-vnexpress-finetuned-wiki-data-raw_data_wseg-lr2e-05-1-epochs-bs-48',\n",
    "          'iambestfeed/phobert-base-v2-vne_wiki_pair_data-raw_data_wseg-lr2e-05-1-epochs-bs-48',\n",
    "          'iambestfeed/phobert-base-v2-vne-finetune-Ecommerce-raw_data_wseg-lr2e-05-1-epochs-bs-48',\n",
    "          'iambestfeed/phobert-base-v2-ft-eco-vnexpress-data-similarity-raw_data_wseg-lr2e-05-1-epochs-bs-64']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.models import Pooling, Transformer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name iambestfeed/phobert_v2_flax_wiki_32_1e_2e5. Creating a new one with MEAN pooling.\n",
      "/home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/nhan-softzone/miniconda3/envs/processdata/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9801b8fae948e1a786b76e143ba2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/538M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at iambestfeed/phobert_v2_flax_wiki_32_1e_2e5 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e2f96438b64e02b2dded525a9791de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f35ca977f5c4a25a531dbeda6055cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb5ccbf001642b7aad8112ef7a36559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28c9dad962c47adb4f1ed7a00db6275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71bb68d90b184b30934adc1390e1220b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/965 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #262626; text-decoration-color: #262626\">───────────────────────────────────────────────── </span><span style=\"font-weight: bold\">Selected tasks </span><span style=\"color: #262626; text-decoration-color: #262626\"> ─────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;235m───────────────────────────────────────────────── \u001b[0m\u001b[1mSelected tasks \u001b[0m\u001b[38;5;235m ─────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Classification</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mClassification\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - Vietnamese_Student_Sentiment, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2s</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - Vietnamese_Student_Sentiment, \u001b[3;38;5;241ms2s\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - Vietnamese_Student_Topic, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2s</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - Vietnamese_Student_Topic, \u001b[3;38;5;241ms2s\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">    - VMTEB_ViOCD, <span style=\"color: #626262; text-decoration-color: #626262; font-style: italic\">s2s</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "    - VMTEB_ViOCD, \u001b[3;38;5;241ms2s\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/nhan-softzone/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for model_name in models:\n",
    "    model = SentenceTransformer(model_name)\n",
    "    model.max_seq_length = 256\n",
    "    pooling_model = Pooling(model[0].get_word_embedding_dimension(), \"mean\")\n",
    "    model[1] = pooling_model\n",
    "\n",
    "    evaluation = MTEB(tasks=[\"Vietnamese_Student_Sentiment\", \"Vietnamese_Student_Topic\", \"VMTEB_ViOCD\"])\n",
    "\n",
    "    result = evaluation.run(model,\n",
    "                            output_folder=f\"vi_results/{model_name}\",\n",
    "                            overwrite_results = True,\n",
    "                            batch_size = 2)\n",
    "    \n",
    "    results[model_name] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iambestfeed/phobert_v2_flax_wiki_32_1e_2e5': {'Vietnamese_Student_Sentiment': {'mteb_version': '1.1.3.dev0',\n",
       "   'dataset_revision': None,\n",
       "   'mteb_dataset_name': 'Vietnamese_Student_Sentiment',\n",
       "   'validation': {'accuracy': 0.5500947567909035,\n",
       "    'f1': 0.4678718118358153,\n",
       "    'accuracy_stderr': 0.019861891355513184,\n",
       "    'f1_stderr': 0.014560275871322017,\n",
       "    'main_score': 0.5500947567909035,\n",
       "    'evaluation_time': 28.81},\n",
       "   'test': {'accuracy': 0.5491787744788377,\n",
       "    'f1': 0.4678886133687765,\n",
       "    'accuracy_stderr': 0.02377665473267239,\n",
       "    'f1_stderr': 0.01642803905905246,\n",
       "    'main_score': 0.5491787744788377,\n",
       "    'evaluation_time': 35.64}},\n",
       "  'Vietnamese_Student_Topic': {'mteb_version': '1.1.3.dev0',\n",
       "   'dataset_revision': None,\n",
       "   'mteb_dataset_name': 'Vietnamese_Student_Topic',\n",
       "   'validation': {'accuracy': 0.5157296272899557,\n",
       "    'f1': 0.3813173681573054,\n",
       "    'accuracy_stderr': 0.03505084876795882,\n",
       "    'f1_stderr': 0.021742246581679156,\n",
       "    'main_score': 0.5157296272899557,\n",
       "    'evaluation_time': 26.97},\n",
       "   'test': {'accuracy': 0.5069172457359443,\n",
       "    'f1': 0.3805785090903448,\n",
       "    'accuracy_stderr': 0.034276834775936404,\n",
       "    'f1_stderr': 0.0155589989443445,\n",
       "    'main_score': 0.5069172457359443,\n",
       "    'evaluation_time': 38.46}},\n",
       "  'VMTEB_ViOCD': {'mteb_version': '1.1.3.dev0',\n",
       "   'dataset_revision': None,\n",
       "   'mteb_dataset_name': 'VMTEB_ViOCD',\n",
       "   'dev': {'accuracy': 0.6755919854280509,\n",
       "    'f1': 0.6741223558522558,\n",
       "    'ap': 0.6248950851706887,\n",
       "    'accuracy_stderr': 0.03242514469758863,\n",
       "    'f1_stderr': 0.033120892988069445,\n",
       "    'ap_stderr': 0.026023818073840577,\n",
       "    'main_score': 0.6755919854280509,\n",
       "    'evaluation_time': 13.35},\n",
       "   'test': {'accuracy': 0.704014598540146,\n",
       "    'f1': 0.702944035483405,\n",
       "    'ap': 0.6571841268569292,\n",
       "    'accuracy_stderr': 0.034803819858050054,\n",
       "    'f1_stderr': 0.03475817914755936,\n",
       "    'ap_stderr': 0.027784905876460757,\n",
       "    'main_score': 0.704014598540146,\n",
       "    'evaluation_time': 9.16}}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert results to DataFrame\n",
    "data = []\n",
    "'''for model_name, model_data in results.items():\n",
    "    for task_name, task_data in model_data.items():\n",
    "        if task_name == 'VMTEB_ViOCD_Wseg' or task_name == 'VMTEB_ViOCD':\n",
    "            task_data_flat = {\n",
    "            \"Model Name\": model_name,\n",
    "            \"Task Name\": task_name,\n",
    "            \"mteb_dataset_name\": task_data[\"mteb_dataset_name\"],\n",
    "            \"Validation Accuracy\": task_data[\"dev\"][\"accuracy\"],\n",
    "            \"Validation F1 Score\": task_data[\"dev\"][\"f1\"],\n",
    "            \"Validation Accuracy StdErr\": task_data[\"dev\"][\"accuracy_stderr\"],\n",
    "            \"Validation F1 Score StdErr\": task_data[\"dev\"][\"f1_stderr\"],\n",
    "            \"Validation Evaluation Time\": task_data[\"dev\"][\"evaluation_time\"],\n",
    "            \"Test Accuracy\": task_data[\"test\"][\"accuracy\"],\n",
    "            \"Test F1 Score\": task_data[\"test\"][\"f1\"],\n",
    "            \"Test Accuracy StdErr\": task_data[\"test\"][\"accuracy_stderr\"],\n",
    "            \"Test F1 Score StdErr\": task_data[\"test\"][\"f1_stderr\"],\n",
    "            \"Test Evaluation Time\": task_data[\"test\"][\"evaluation_time\"]\n",
    "        }\n",
    "        else:\n",
    "            task_data_flat = {\n",
    "                \"Model Name\": model_name,\n",
    "                \"Task Name\": task_name,\n",
    "                \"mteb_dataset_name\": task_data[\"mteb_dataset_name\"],\n",
    "                \"Validation Accuracy\": task_data[\"validation\"][\"accuracy\"],\n",
    "                \"Validation F1 Score\": task_data[\"validation\"][\"f1\"],\n",
    "                \"Validation Accuracy StdErr\": task_data[\"validation\"][\"accuracy_stderr\"],\n",
    "                \"Validation F1 Score StdErr\": task_data[\"validation\"][\"f1_stderr\"],\n",
    "                \"Validation Evaluation Time\": task_data[\"validation\"][\"evaluation_time\"],\n",
    "                \"Test Accuracy\": task_data[\"test\"][\"accuracy\"],\n",
    "                \"Test F1 Score\": task_data[\"test\"][\"f1\"],\n",
    "                \"Test Accuracy StdErr\": task_data[\"test\"][\"accuracy_stderr\"],\n",
    "                \"Test F1 Score StdErr\": task_data[\"test\"][\"f1_stderr\"],\n",
    "                \"Test Evaluation Time\": task_data[\"test\"][\"evaluation_time\"]\n",
    "            }\n",
    "        data.append(task_data_flat)'''\n",
    "        \n",
    "for model_name, model_data in results.items():\n",
    "    for task_name, task_data in model_data.items():\n",
    "        if task_name == 'VMTEB_ViOCD_Wseg' or task_name == 'VMTEB_ViOCD':\n",
    "            task_data_flat = {\n",
    "            \"Model Name\": model_name,\n",
    "            \"Task Name\": task_name,\n",
    "            \"Validation Accuracy\": task_data[\"dev\"][\"accuracy\"],\n",
    "            \"Validation F1 Score\": task_data[\"dev\"][\"f1\"],\n",
    "            \"Test Accuracy\": task_data[\"test\"][\"accuracy\"],\n",
    "            \"Test F1 Score\": task_data[\"test\"][\"f1\"],\n",
    "        }\n",
    "        else:\n",
    "            task_data_flat = {\n",
    "                \"Model Name\": model_name,\n",
    "                \"Task Name\": task_name,\n",
    "                \"Validation Accuracy\": task_data[\"validation\"][\"accuracy\"],\n",
    "                \"Validation F1 Score\": task_data[\"validation\"][\"f1\"],\n",
    "                \"Test Accuracy\": task_data[\"test\"][\"accuracy\"],\n",
    "                \"Test F1 Score\": task_data[\"test\"][\"f1\"],\n",
    "            }\n",
    "        data.append(task_data_flat)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Task Name</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation F1 Score</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iambestfeed/phobert_v2_flax_wiki_32_1e_2e5</td>\n",
       "      <td>Vietnamese_Student_Sentiment</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.467872</td>\n",
       "      <td>0.549179</td>\n",
       "      <td>0.467889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iambestfeed/phobert_v2_flax_wiki_32_1e_2e5</td>\n",
       "      <td>Vietnamese_Student_Topic</td>\n",
       "      <td>0.515730</td>\n",
       "      <td>0.381317</td>\n",
       "      <td>0.506917</td>\n",
       "      <td>0.380579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iambestfeed/phobert_v2_flax_wiki_32_1e_2e5</td>\n",
       "      <td>VMTEB_ViOCD</td>\n",
       "      <td>0.675592</td>\n",
       "      <td>0.674122</td>\n",
       "      <td>0.704015</td>\n",
       "      <td>0.702944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Name                     Task Name  \\\n",
       "0  iambestfeed/phobert_v2_flax_wiki_32_1e_2e5  Vietnamese_Student_Sentiment   \n",
       "1  iambestfeed/phobert_v2_flax_wiki_32_1e_2e5      Vietnamese_Student_Topic   \n",
       "2  iambestfeed/phobert_v2_flax_wiki_32_1e_2e5                   VMTEB_ViOCD   \n",
       "\n",
       "   Validation Accuracy  Validation F1 Score  Test Accuracy  Test F1 Score  \n",
       "0             0.550095             0.467872       0.549179       0.467889  \n",
       "1             0.515730             0.381317       0.506917       0.380579  \n",
       "2             0.675592             0.674122       0.704015       0.702944  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Task Name</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation F1 Score</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vinai/phobert-base-v2</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.756791</td>\n",
       "      <td>0.636052</td>\n",
       "      <td>0.735313</td>\n",
       "      <td>0.619453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vinai/phobert-base-v2</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.693872</td>\n",
       "      <td>0.602146</td>\n",
       "      <td>0.680670</td>\n",
       "      <td>0.588806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vinai/phobert-base-v2</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.802737</td>\n",
       "      <td>0.802440</td>\n",
       "      <td>0.834307</td>\n",
       "      <td>0.833937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-raw_data...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.772268</td>\n",
       "      <td>0.643732</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>0.638303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-raw_data...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.713771</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>0.700253</td>\n",
       "      <td>0.621357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-raw_data...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.833577</td>\n",
       "      <td>0.833431</td>\n",
       "      <td>0.845620</td>\n",
       "      <td>0.845490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-wiki-dat...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.790272</td>\n",
       "      <td>0.659271</td>\n",
       "      <td>0.781744</td>\n",
       "      <td>0.659002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-wiki-dat...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.744220</td>\n",
       "      <td>0.660763</td>\n",
       "      <td>0.733449</td>\n",
       "      <td>0.645151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-wiki-dat...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.853650</td>\n",
       "      <td>0.853503</td>\n",
       "      <td>0.869343</td>\n",
       "      <td>0.869178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iambestfeed/phobert-base-v2-Vietnamese-Ecommer...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.754454</td>\n",
       "      <td>0.629339</td>\n",
       "      <td>0.741725</td>\n",
       "      <td>0.624205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>iambestfeed/phobert-base-v2-Vietnamese-Ecommer...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.711623</td>\n",
       "      <td>0.619203</td>\n",
       "      <td>0.701074</td>\n",
       "      <td>0.608072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>iambestfeed/phobert-base-v2-Vietnamese-Ecommer...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.847263</td>\n",
       "      <td>0.847140</td>\n",
       "      <td>0.862774</td>\n",
       "      <td>0.862524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-wiki-fi...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.779659</td>\n",
       "      <td>0.645178</td>\n",
       "      <td>0.767340</td>\n",
       "      <td>0.646270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-wiki-fi...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.720341</td>\n",
       "      <td>0.645010</td>\n",
       "      <td>0.709539</td>\n",
       "      <td>0.632396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-wiki-fi...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.841423</td>\n",
       "      <td>0.841247</td>\n",
       "      <td>0.861496</td>\n",
       "      <td>0.861279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-vnexpre...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.800063</td>\n",
       "      <td>0.665917</td>\n",
       "      <td>0.790777</td>\n",
       "      <td>0.668062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-vnexpre...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.736197</td>\n",
       "      <td>0.653826</td>\n",
       "      <td>0.727006</td>\n",
       "      <td>0.640689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-vnexpre...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.857664</td>\n",
       "      <td>0.857540</td>\n",
       "      <td>0.868796</td>\n",
       "      <td>0.868662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne_wiki_pair_data...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.778522</td>\n",
       "      <td>0.643432</td>\n",
       "      <td>0.764087</td>\n",
       "      <td>0.642386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne_wiki_pair_data...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.729501</td>\n",
       "      <td>0.648118</td>\n",
       "      <td>0.716109</td>\n",
       "      <td>0.631840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne_wiki_pair_data...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.817701</td>\n",
       "      <td>0.817556</td>\n",
       "      <td>0.842153</td>\n",
       "      <td>0.842012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne-finetune-Ecomm...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.760455</td>\n",
       "      <td>0.634173</td>\n",
       "      <td>0.744125</td>\n",
       "      <td>0.627777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne-finetune-Ecomm...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.714214</td>\n",
       "      <td>0.625805</td>\n",
       "      <td>0.699147</td>\n",
       "      <td>0.612137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne-finetune-Ecomm...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.843066</td>\n",
       "      <td>0.842950</td>\n",
       "      <td>0.859307</td>\n",
       "      <td>0.859135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.772394</td>\n",
       "      <td>0.642527</td>\n",
       "      <td>0.756886</td>\n",
       "      <td>0.638529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.713519</td>\n",
       "      <td>0.636166</td>\n",
       "      <td>0.700442</td>\n",
       "      <td>0.621238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.837956</td>\n",
       "      <td>0.837855</td>\n",
       "      <td>0.856022</td>\n",
       "      <td>0.855908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  \\\n",
       "0                               vinai/phobert-base-v2   \n",
       "1                               vinai/phobert-base-v2   \n",
       "2                               vinai/phobert-base-v2   \n",
       "3   iambestfeed/phobert-base-v2-finetuned-raw_data...   \n",
       "4   iambestfeed/phobert-base-v2-finetuned-raw_data...   \n",
       "5   iambestfeed/phobert-base-v2-finetuned-raw_data...   \n",
       "6   iambestfeed/phobert-base-v2-finetuned-wiki-dat...   \n",
       "7   iambestfeed/phobert-base-v2-finetuned-wiki-dat...   \n",
       "8   iambestfeed/phobert-base-v2-finetuned-wiki-dat...   \n",
       "9   iambestfeed/phobert-base-v2-Vietnamese-Ecommer...   \n",
       "10  iambestfeed/phobert-base-v2-Vietnamese-Ecommer...   \n",
       "11  iambestfeed/phobert-base-v2-Vietnamese-Ecommer...   \n",
       "12  iambestfeed/phobert-base-v2-finetuneed-wiki-fi...   \n",
       "13  iambestfeed/phobert-base-v2-finetuneed-wiki-fi...   \n",
       "14  iambestfeed/phobert-base-v2-finetuneed-wiki-fi...   \n",
       "15  iambestfeed/phobert-base-v2-finetuneed-vnexpre...   \n",
       "16  iambestfeed/phobert-base-v2-finetuneed-vnexpre...   \n",
       "17  iambestfeed/phobert-base-v2-finetuneed-vnexpre...   \n",
       "18  iambestfeed/phobert-base-v2-vne_wiki_pair_data...   \n",
       "19  iambestfeed/phobert-base-v2-vne_wiki_pair_data...   \n",
       "20  iambestfeed/phobert-base-v2-vne_wiki_pair_data...   \n",
       "21  iambestfeed/phobert-base-v2-vne-finetune-Ecomm...   \n",
       "22  iambestfeed/phobert-base-v2-vne-finetune-Ecomm...   \n",
       "23  iambestfeed/phobert-base-v2-vne-finetune-Ecomm...   \n",
       "24  iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...   \n",
       "25  iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...   \n",
       "26  iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...   \n",
       "\n",
       "                            Task Name  Validation Accuracy  \\\n",
       "0   Vietnamese_Student_Sentiment_Wseg             0.756791   \n",
       "1       Vietnamese_Student_Topic_Wseg             0.693872   \n",
       "2                    VMTEB_ViOCD_Wseg             0.802737   \n",
       "3   Vietnamese_Student_Sentiment_Wseg             0.772268   \n",
       "4       Vietnamese_Student_Topic_Wseg             0.713771   \n",
       "5                    VMTEB_ViOCD_Wseg             0.833577   \n",
       "6   Vietnamese_Student_Sentiment_Wseg             0.790272   \n",
       "7       Vietnamese_Student_Topic_Wseg             0.744220   \n",
       "8                    VMTEB_ViOCD_Wseg             0.853650   \n",
       "9   Vietnamese_Student_Sentiment_Wseg             0.754454   \n",
       "10      Vietnamese_Student_Topic_Wseg             0.711623   \n",
       "11                   VMTEB_ViOCD_Wseg             0.847263   \n",
       "12  Vietnamese_Student_Sentiment_Wseg             0.779659   \n",
       "13      Vietnamese_Student_Topic_Wseg             0.720341   \n",
       "14                   VMTEB_ViOCD_Wseg             0.841423   \n",
       "15  Vietnamese_Student_Sentiment_Wseg             0.800063   \n",
       "16      Vietnamese_Student_Topic_Wseg             0.736197   \n",
       "17                   VMTEB_ViOCD_Wseg             0.857664   \n",
       "18  Vietnamese_Student_Sentiment_Wseg             0.778522   \n",
       "19      Vietnamese_Student_Topic_Wseg             0.729501   \n",
       "20                   VMTEB_ViOCD_Wseg             0.817701   \n",
       "21  Vietnamese_Student_Sentiment_Wseg             0.760455   \n",
       "22      Vietnamese_Student_Topic_Wseg             0.714214   \n",
       "23                   VMTEB_ViOCD_Wseg             0.843066   \n",
       "24  Vietnamese_Student_Sentiment_Wseg             0.772394   \n",
       "25      Vietnamese_Student_Topic_Wseg             0.713519   \n",
       "26                   VMTEB_ViOCD_Wseg             0.837956   \n",
       "\n",
       "    Validation F1 Score  Test Accuracy  Test F1 Score  \n",
       "0              0.636052       0.735313       0.619453  \n",
       "1              0.602146       0.680670       0.588806  \n",
       "2              0.802440       0.834307       0.833937  \n",
       "3              0.643732       0.756728       0.638303  \n",
       "4              0.633714       0.700253       0.621357  \n",
       "5              0.833431       0.845620       0.845490  \n",
       "6              0.659271       0.781744       0.659002  \n",
       "7              0.660763       0.733449       0.645151  \n",
       "8              0.853503       0.869343       0.869178  \n",
       "9              0.629339       0.741725       0.624205  \n",
       "10             0.619203       0.701074       0.608072  \n",
       "11             0.847140       0.862774       0.862524  \n",
       "12             0.645178       0.767340       0.646270  \n",
       "13             0.645010       0.709539       0.632396  \n",
       "14             0.841247       0.861496       0.861279  \n",
       "15             0.665917       0.790777       0.668062  \n",
       "16             0.653826       0.727006       0.640689  \n",
       "17             0.857540       0.868796       0.868662  \n",
       "18             0.643432       0.764087       0.642386  \n",
       "19             0.648118       0.716109       0.631840  \n",
       "20             0.817556       0.842153       0.842012  \n",
       "21             0.634173       0.744125       0.627777  \n",
       "22             0.625805       0.699147       0.612137  \n",
       "23             0.842950       0.859307       0.859135  \n",
       "24             0.642527       0.756886       0.638529  \n",
       "25             0.636166       0.700442       0.621238  \n",
       "26             0.837855       0.856022       0.855908  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Task Name</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation F1 Score</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vinai/phobert-base-v2</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.756791</td>\n",
       "      <td>0.636052</td>\n",
       "      <td>0.735313</td>\n",
       "      <td>0.619453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vinai/phobert-base-v2</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.693872</td>\n",
       "      <td>0.602146</td>\n",
       "      <td>0.680670</td>\n",
       "      <td>0.588806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vinai/phobert-base-v2</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.802737</td>\n",
       "      <td>0.802440</td>\n",
       "      <td>0.834307</td>\n",
       "      <td>0.833937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-raw_data...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.772268</td>\n",
       "      <td>0.643732</td>\n",
       "      <td>0.756728</td>\n",
       "      <td>0.638303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-raw_data...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.713771</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>0.700253</td>\n",
       "      <td>0.621357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-raw_data...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.833577</td>\n",
       "      <td>0.833431</td>\n",
       "      <td>0.845620</td>\n",
       "      <td>0.845490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-wiki-dat...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.790272</td>\n",
       "      <td>0.659271</td>\n",
       "      <td>0.781744</td>\n",
       "      <td>0.659002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-wiki-dat...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.744220</td>\n",
       "      <td>0.660763</td>\n",
       "      <td>0.733449</td>\n",
       "      <td>0.645151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-wiki-dat...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.853650</td>\n",
       "      <td>0.853503</td>\n",
       "      <td>0.869343</td>\n",
       "      <td>0.869178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iambestfeed/phobert-base-v2-Vietnamese-Ecommer...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.754454</td>\n",
       "      <td>0.629339</td>\n",
       "      <td>0.741725</td>\n",
       "      <td>0.624205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>iambestfeed/phobert-base-v2-Vietnamese-Ecommer...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.711623</td>\n",
       "      <td>0.619203</td>\n",
       "      <td>0.701074</td>\n",
       "      <td>0.608072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>iambestfeed/phobert-base-v2-Vietnamese-Ecommer...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.847263</td>\n",
       "      <td>0.847140</td>\n",
       "      <td>0.862774</td>\n",
       "      <td>0.862524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-wiki-fi...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.779659</td>\n",
       "      <td>0.645178</td>\n",
       "      <td>0.767340</td>\n",
       "      <td>0.646270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-wiki-fi...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.720341</td>\n",
       "      <td>0.645010</td>\n",
       "      <td>0.709539</td>\n",
       "      <td>0.632396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-wiki-fi...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.841423</td>\n",
       "      <td>0.841247</td>\n",
       "      <td>0.861496</td>\n",
       "      <td>0.861279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-vnexpre...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.800063</td>\n",
       "      <td>0.665917</td>\n",
       "      <td>0.790777</td>\n",
       "      <td>0.668062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-vnexpre...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.736197</td>\n",
       "      <td>0.653826</td>\n",
       "      <td>0.727006</td>\n",
       "      <td>0.640689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-vnexpre...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.857664</td>\n",
       "      <td>0.857540</td>\n",
       "      <td>0.868796</td>\n",
       "      <td>0.868662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne_wiki_pair_data...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.778522</td>\n",
       "      <td>0.643432</td>\n",
       "      <td>0.764087</td>\n",
       "      <td>0.642386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne_wiki_pair_data...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.729501</td>\n",
       "      <td>0.648118</td>\n",
       "      <td>0.716109</td>\n",
       "      <td>0.631840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne_wiki_pair_data...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.817701</td>\n",
       "      <td>0.817556</td>\n",
       "      <td>0.842153</td>\n",
       "      <td>0.842012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne-finetune-Ecomm...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.760455</td>\n",
       "      <td>0.634173</td>\n",
       "      <td>0.744125</td>\n",
       "      <td>0.627777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne-finetune-Ecomm...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.714214</td>\n",
       "      <td>0.625805</td>\n",
       "      <td>0.699147</td>\n",
       "      <td>0.612137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne-finetune-Ecomm...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.843066</td>\n",
       "      <td>0.842950</td>\n",
       "      <td>0.859307</td>\n",
       "      <td>0.859135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.772394</td>\n",
       "      <td>0.642527</td>\n",
       "      <td>0.756886</td>\n",
       "      <td>0.638529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.713519</td>\n",
       "      <td>0.636166</td>\n",
       "      <td>0.700442</td>\n",
       "      <td>0.621238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.837956</td>\n",
       "      <td>0.837855</td>\n",
       "      <td>0.856022</td>\n",
       "      <td>0.855908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  \\\n",
       "0                               vinai/phobert-base-v2   \n",
       "1                               vinai/phobert-base-v2   \n",
       "2                               vinai/phobert-base-v2   \n",
       "3   iambestfeed/phobert-base-v2-finetuned-raw_data...   \n",
       "4   iambestfeed/phobert-base-v2-finetuned-raw_data...   \n",
       "5   iambestfeed/phobert-base-v2-finetuned-raw_data...   \n",
       "6   iambestfeed/phobert-base-v2-finetuned-wiki-dat...   \n",
       "7   iambestfeed/phobert-base-v2-finetuned-wiki-dat...   \n",
       "8   iambestfeed/phobert-base-v2-finetuned-wiki-dat...   \n",
       "9   iambestfeed/phobert-base-v2-Vietnamese-Ecommer...   \n",
       "10  iambestfeed/phobert-base-v2-Vietnamese-Ecommer...   \n",
       "11  iambestfeed/phobert-base-v2-Vietnamese-Ecommer...   \n",
       "12  iambestfeed/phobert-base-v2-finetuneed-wiki-fi...   \n",
       "13  iambestfeed/phobert-base-v2-finetuneed-wiki-fi...   \n",
       "14  iambestfeed/phobert-base-v2-finetuneed-wiki-fi...   \n",
       "15  iambestfeed/phobert-base-v2-finetuneed-vnexpre...   \n",
       "16  iambestfeed/phobert-base-v2-finetuneed-vnexpre...   \n",
       "17  iambestfeed/phobert-base-v2-finetuneed-vnexpre...   \n",
       "18  iambestfeed/phobert-base-v2-vne_wiki_pair_data...   \n",
       "19  iambestfeed/phobert-base-v2-vne_wiki_pair_data...   \n",
       "20  iambestfeed/phobert-base-v2-vne_wiki_pair_data...   \n",
       "21  iambestfeed/phobert-base-v2-vne-finetune-Ecomm...   \n",
       "22  iambestfeed/phobert-base-v2-vne-finetune-Ecomm...   \n",
       "23  iambestfeed/phobert-base-v2-vne-finetune-Ecomm...   \n",
       "24  iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...   \n",
       "25  iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...   \n",
       "26  iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...   \n",
       "\n",
       "                            Task Name  Validation Accuracy  \\\n",
       "0   Vietnamese_Student_Sentiment_Wseg             0.756791   \n",
       "1       Vietnamese_Student_Topic_Wseg             0.693872   \n",
       "2                    VMTEB_ViOCD_Wseg             0.802737   \n",
       "3   Vietnamese_Student_Sentiment_Wseg             0.772268   \n",
       "4       Vietnamese_Student_Topic_Wseg             0.713771   \n",
       "5                    VMTEB_ViOCD_Wseg             0.833577   \n",
       "6   Vietnamese_Student_Sentiment_Wseg             0.790272   \n",
       "7       Vietnamese_Student_Topic_Wseg             0.744220   \n",
       "8                    VMTEB_ViOCD_Wseg             0.853650   \n",
       "9   Vietnamese_Student_Sentiment_Wseg             0.754454   \n",
       "10      Vietnamese_Student_Topic_Wseg             0.711623   \n",
       "11                   VMTEB_ViOCD_Wseg             0.847263   \n",
       "12  Vietnamese_Student_Sentiment_Wseg             0.779659   \n",
       "13      Vietnamese_Student_Topic_Wseg             0.720341   \n",
       "14                   VMTEB_ViOCD_Wseg             0.841423   \n",
       "15  Vietnamese_Student_Sentiment_Wseg             0.800063   \n",
       "16      Vietnamese_Student_Topic_Wseg             0.736197   \n",
       "17                   VMTEB_ViOCD_Wseg             0.857664   \n",
       "18  Vietnamese_Student_Sentiment_Wseg             0.778522   \n",
       "19      Vietnamese_Student_Topic_Wseg             0.729501   \n",
       "20                   VMTEB_ViOCD_Wseg             0.817701   \n",
       "21  Vietnamese_Student_Sentiment_Wseg             0.760455   \n",
       "22      Vietnamese_Student_Topic_Wseg             0.714214   \n",
       "23                   VMTEB_ViOCD_Wseg             0.843066   \n",
       "24  Vietnamese_Student_Sentiment_Wseg             0.772394   \n",
       "25      Vietnamese_Student_Topic_Wseg             0.713519   \n",
       "26                   VMTEB_ViOCD_Wseg             0.837956   \n",
       "\n",
       "    Validation F1 Score  Test Accuracy  Test F1 Score  \n",
       "0              0.636052       0.735313       0.619453  \n",
       "1              0.602146       0.680670       0.588806  \n",
       "2              0.802440       0.834307       0.833937  \n",
       "3              0.643732       0.756728       0.638303  \n",
       "4              0.633714       0.700253       0.621357  \n",
       "5              0.833431       0.845620       0.845490  \n",
       "6              0.659271       0.781744       0.659002  \n",
       "7              0.660763       0.733449       0.645151  \n",
       "8              0.853503       0.869343       0.869178  \n",
       "9              0.629339       0.741725       0.624205  \n",
       "10             0.619203       0.701074       0.608072  \n",
       "11             0.847140       0.862774       0.862524  \n",
       "12             0.645178       0.767340       0.646270  \n",
       "13             0.645010       0.709539       0.632396  \n",
       "14             0.841247       0.861496       0.861279  \n",
       "15             0.665917       0.790777       0.668062  \n",
       "16             0.653826       0.727006       0.640689  \n",
       "17             0.857540       0.868796       0.868662  \n",
       "18             0.643432       0.764087       0.642386  \n",
       "19             0.648118       0.716109       0.631840  \n",
       "20             0.817556       0.842153       0.842012  \n",
       "21             0.634173       0.744125       0.627777  \n",
       "22             0.625805       0.699147       0.612137  \n",
       "23             0.842950       0.859307       0.859135  \n",
       "24             0.642527       0.756886       0.638529  \n",
       "25             0.636166       0.700442       0.621238  \n",
       "26             0.837855       0.856022       0.855908  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính % cải thiện so với baseline cho từng task\n",
    "baseline = df[df[\"Model Name\"] == \"vinai/phobert-base-v2\"].set_index(\"Task Name\")\n",
    "metrics = [\"Validation Accuracy\", \"Validation F1 Score\", \"Test Accuracy\", \"Test F1 Score\"]\n",
    "\n",
    "for metric in metrics:\n",
    "    df[f\"% Improvement {metric}\"] = df.apply(\n",
    "        lambda row: ((row[metric] - baseline.loc[row[\"Task Name\"], metric]) / \n",
    "                     baseline.loc[row[\"Task Name\"], metric]) * 100, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Task Name</th>\n",
       "      <th>% Improvement Validation Accuracy</th>\n",
       "      <th>% Improvement Validation F1 Score</th>\n",
       "      <th>% Improvement Test Accuracy</th>\n",
       "      <th>% Improvement Test F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vinai/phobert-base-v2</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vinai/phobert-base-v2</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vinai/phobert-base-v2</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-raw_data...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>2.045075</td>\n",
       "      <td>1.207535</td>\n",
       "      <td>2.912371</td>\n",
       "      <td>3.043058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-raw_data...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>2.867808</td>\n",
       "      <td>5.242545</td>\n",
       "      <td>2.877030</td>\n",
       "      <td>5.528313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-raw_data...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>3.841782</td>\n",
       "      <td>3.862156</td>\n",
       "      <td>1.356080</td>\n",
       "      <td>1.385413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-wiki-dat...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>4.424040</td>\n",
       "      <td>3.650472</td>\n",
       "      <td>6.314433</td>\n",
       "      <td>6.384492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-wiki-dat...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>7.256009</td>\n",
       "      <td>9.734677</td>\n",
       "      <td>7.754060</td>\n",
       "      <td>9.569451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuned-wiki-dat...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>6.342351</td>\n",
       "      <td>6.363526</td>\n",
       "      <td>4.199475</td>\n",
       "      <td>4.225875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iambestfeed/phobert-base-v2-Vietnamese-Ecommer...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>-0.308848</td>\n",
       "      <td>-1.055444</td>\n",
       "      <td>0.871993</td>\n",
       "      <td>0.767187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>iambestfeed/phobert-base-v2-Vietnamese-Ecommer...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>2.558267</td>\n",
       "      <td>2.832746</td>\n",
       "      <td>2.997680</td>\n",
       "      <td>3.272096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>iambestfeed/phobert-base-v2-Vietnamese-Ecommer...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>5.546715</td>\n",
       "      <td>5.570507</td>\n",
       "      <td>3.412073</td>\n",
       "      <td>3.427927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-wiki-fi...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>3.021703</td>\n",
       "      <td>1.434750</td>\n",
       "      <td>4.355670</td>\n",
       "      <td>4.329261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-wiki-fi...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>3.814639</td>\n",
       "      <td>7.118585</td>\n",
       "      <td>4.241299</td>\n",
       "      <td>7.403071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-wiki-fi...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>4.819277</td>\n",
       "      <td>4.836121</td>\n",
       "      <td>3.258968</td>\n",
       "      <td>3.278718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-vnexpre...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>5.717863</td>\n",
       "      <td>4.695340</td>\n",
       "      <td>7.542955</td>\n",
       "      <td>7.847099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-vnexpre...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>6.099782</td>\n",
       "      <td>8.582739</td>\n",
       "      <td>6.807425</td>\n",
       "      <td>8.811557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>iambestfeed/phobert-base-v2-finetuneed-vnexpre...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>6.842464</td>\n",
       "      <td>6.866518</td>\n",
       "      <td>4.133858</td>\n",
       "      <td>4.164008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne_wiki_pair_data...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>2.871452</td>\n",
       "      <td>1.160316</td>\n",
       "      <td>3.913230</td>\n",
       "      <td>3.702237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne_wiki_pair_data...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>5.134741</td>\n",
       "      <td>7.634665</td>\n",
       "      <td>5.206497</td>\n",
       "      <td>7.308710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne_wiki_pair_data...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>1.864060</td>\n",
       "      <td>1.883751</td>\n",
       "      <td>0.940507</td>\n",
       "      <td>0.968333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne-finetune-Ecomm...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.484140</td>\n",
       "      <td>-0.295299</td>\n",
       "      <td>1.198454</td>\n",
       "      <td>1.343742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne-finetune-Ecomm...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>2.931537</td>\n",
       "      <td>3.929231</td>\n",
       "      <td>2.714617</td>\n",
       "      <td>3.962388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>iambestfeed/phobert-base-v2-vne-finetune-Ecomm...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>5.023869</td>\n",
       "      <td>5.048330</td>\n",
       "      <td>2.996500</td>\n",
       "      <td>3.021538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>2.061770</td>\n",
       "      <td>1.018078</td>\n",
       "      <td>2.933849</td>\n",
       "      <td>3.079520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>2.831391</td>\n",
       "      <td>5.649775</td>\n",
       "      <td>2.904872</td>\n",
       "      <td>5.508036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>4.387361</td>\n",
       "      <td>4.413404</td>\n",
       "      <td>2.602800</td>\n",
       "      <td>2.634683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Model Name  \\\n",
       "0                               vinai/phobert-base-v2   \n",
       "1                               vinai/phobert-base-v2   \n",
       "2                               vinai/phobert-base-v2   \n",
       "3   iambestfeed/phobert-base-v2-finetuned-raw_data...   \n",
       "4   iambestfeed/phobert-base-v2-finetuned-raw_data...   \n",
       "5   iambestfeed/phobert-base-v2-finetuned-raw_data...   \n",
       "6   iambestfeed/phobert-base-v2-finetuned-wiki-dat...   \n",
       "7   iambestfeed/phobert-base-v2-finetuned-wiki-dat...   \n",
       "8   iambestfeed/phobert-base-v2-finetuned-wiki-dat...   \n",
       "9   iambestfeed/phobert-base-v2-Vietnamese-Ecommer...   \n",
       "10  iambestfeed/phobert-base-v2-Vietnamese-Ecommer...   \n",
       "11  iambestfeed/phobert-base-v2-Vietnamese-Ecommer...   \n",
       "12  iambestfeed/phobert-base-v2-finetuneed-wiki-fi...   \n",
       "13  iambestfeed/phobert-base-v2-finetuneed-wiki-fi...   \n",
       "14  iambestfeed/phobert-base-v2-finetuneed-wiki-fi...   \n",
       "15  iambestfeed/phobert-base-v2-finetuneed-vnexpre...   \n",
       "16  iambestfeed/phobert-base-v2-finetuneed-vnexpre...   \n",
       "17  iambestfeed/phobert-base-v2-finetuneed-vnexpre...   \n",
       "18  iambestfeed/phobert-base-v2-vne_wiki_pair_data...   \n",
       "19  iambestfeed/phobert-base-v2-vne_wiki_pair_data...   \n",
       "20  iambestfeed/phobert-base-v2-vne_wiki_pair_data...   \n",
       "21  iambestfeed/phobert-base-v2-vne-finetune-Ecomm...   \n",
       "22  iambestfeed/phobert-base-v2-vne-finetune-Ecomm...   \n",
       "23  iambestfeed/phobert-base-v2-vne-finetune-Ecomm...   \n",
       "24  iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...   \n",
       "25  iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...   \n",
       "26  iambestfeed/phobert-base-v2-ft-eco-vnexpress-d...   \n",
       "\n",
       "                            Task Name  % Improvement Validation Accuracy  \\\n",
       "0   Vietnamese_Student_Sentiment_Wseg                           0.000000   \n",
       "1       Vietnamese_Student_Topic_Wseg                           0.000000   \n",
       "2                    VMTEB_ViOCD_Wseg                           0.000000   \n",
       "3   Vietnamese_Student_Sentiment_Wseg                           2.045075   \n",
       "4       Vietnamese_Student_Topic_Wseg                           2.867808   \n",
       "5                    VMTEB_ViOCD_Wseg                           3.841782   \n",
       "6   Vietnamese_Student_Sentiment_Wseg                           4.424040   \n",
       "7       Vietnamese_Student_Topic_Wseg                           7.256009   \n",
       "8                    VMTEB_ViOCD_Wseg                           6.342351   \n",
       "9   Vietnamese_Student_Sentiment_Wseg                          -0.308848   \n",
       "10      Vietnamese_Student_Topic_Wseg                           2.558267   \n",
       "11                   VMTEB_ViOCD_Wseg                           5.546715   \n",
       "12  Vietnamese_Student_Sentiment_Wseg                           3.021703   \n",
       "13      Vietnamese_Student_Topic_Wseg                           3.814639   \n",
       "14                   VMTEB_ViOCD_Wseg                           4.819277   \n",
       "15  Vietnamese_Student_Sentiment_Wseg                           5.717863   \n",
       "16      Vietnamese_Student_Topic_Wseg                           6.099782   \n",
       "17                   VMTEB_ViOCD_Wseg                           6.842464   \n",
       "18  Vietnamese_Student_Sentiment_Wseg                           2.871452   \n",
       "19      Vietnamese_Student_Topic_Wseg                           5.134741   \n",
       "20                   VMTEB_ViOCD_Wseg                           1.864060   \n",
       "21  Vietnamese_Student_Sentiment_Wseg                           0.484140   \n",
       "22      Vietnamese_Student_Topic_Wseg                           2.931537   \n",
       "23                   VMTEB_ViOCD_Wseg                           5.023869   \n",
       "24  Vietnamese_Student_Sentiment_Wseg                           2.061770   \n",
       "25      Vietnamese_Student_Topic_Wseg                           2.831391   \n",
       "26                   VMTEB_ViOCD_Wseg                           4.387361   \n",
       "\n",
       "    % Improvement Validation F1 Score  % Improvement Test Accuracy  \\\n",
       "0                            0.000000                     0.000000   \n",
       "1                            0.000000                     0.000000   \n",
       "2                            0.000000                     0.000000   \n",
       "3                            1.207535                     2.912371   \n",
       "4                            5.242545                     2.877030   \n",
       "5                            3.862156                     1.356080   \n",
       "6                            3.650472                     6.314433   \n",
       "7                            9.734677                     7.754060   \n",
       "8                            6.363526                     4.199475   \n",
       "9                           -1.055444                     0.871993   \n",
       "10                           2.832746                     2.997680   \n",
       "11                           5.570507                     3.412073   \n",
       "12                           1.434750                     4.355670   \n",
       "13                           7.118585                     4.241299   \n",
       "14                           4.836121                     3.258968   \n",
       "15                           4.695340                     7.542955   \n",
       "16                           8.582739                     6.807425   \n",
       "17                           6.866518                     4.133858   \n",
       "18                           1.160316                     3.913230   \n",
       "19                           7.634665                     5.206497   \n",
       "20                           1.883751                     0.940507   \n",
       "21                          -0.295299                     1.198454   \n",
       "22                           3.929231                     2.714617   \n",
       "23                           5.048330                     2.996500   \n",
       "24                           1.018078                     2.933849   \n",
       "25                           5.649775                     2.904872   \n",
       "26                           4.413404                     2.602800   \n",
       "\n",
       "    % Improvement Test F1 Score  \n",
       "0                      0.000000  \n",
       "1                      0.000000  \n",
       "2                      0.000000  \n",
       "3                      3.043058  \n",
       "4                      5.528313  \n",
       "5                      1.385413  \n",
       "6                      6.384492  \n",
       "7                      9.569451  \n",
       "8                      4.225875  \n",
       "9                      0.767187  \n",
       "10                     3.272096  \n",
       "11                     3.427927  \n",
       "12                     4.329261  \n",
       "13                     7.403071  \n",
       "14                     3.278718  \n",
       "15                     7.847099  \n",
       "16                     8.811557  \n",
       "17                     4.164008  \n",
       "18                     3.702237  \n",
       "19                     7.308710  \n",
       "20                     0.968333  \n",
       "21                     1.343742  \n",
       "22                     3.962388  \n",
       "23                     3.021538  \n",
       "24                     3.079520  \n",
       "25                     5.508036  \n",
       "26                     2.634683  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Model Name\", \"Task Name\", \"% Improvement Validation Accuracy\", \n",
    "          \"% Improvement Validation F1 Score\", \"% Improvement Test Accuracy\", \n",
    "          \"% Improvement Test F1 Score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_improve = df[[\"Model Name\", \"Task Name\", \"% Improvement Validation Accuracy\", \n",
    "          \"% Improvement Validation F1 Score\", \"% Improvement Test Accuracy\", \n",
    "          \"% Improvement Test F1 Score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2301905/3798153898.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_improve[\"Model Name\"] = df_improve[\"Model Name\"].apply(shorten_model_name)\n"
     ]
    }
   ],
   "source": [
    "def shorten_model_name(name):\n",
    "    name = name.replace(\"iambestfeed/phobert-base-v2-\", \"\")\n",
    "    name = name.replace(\"finetuned-\", \"ft-\")\n",
    "    name = name.replace(\"finetuneed-\", \"ft-\")  # Fix typo in some names\n",
    "    name = name.replace(\"raw_data_wseg\", \"rdw\")\n",
    "    name = name.replace(\"wiki-data\", \"wiki\")\n",
    "    name = name.replace(\"vnexpress\", \"vne\")\n",
    "    name = name.replace(\"lr2e-05\", \"lr2e5\")\n",
    "    name = name.replace(\"lr5e-06\", \"lr5e6\")\n",
    "    name = name.replace(\"epochs\", \"ep\")\n",
    "    name = name.replace(\"batch size\", \"bs\")\n",
    "    name = name.replace(\"Ecommerce\", 'eco')\n",
    "    name = name.replace(\"finetune-\", \"ft-\")\n",
    "    return name\n",
    "\n",
    "# Apply shortening function\n",
    "df_improve[\"Model Name\"] = df_improve[\"Model Name\"].apply(shorten_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Task Name</th>\n",
       "      <th>% Improvement Validation Accuracy</th>\n",
       "      <th>% Improvement Validation F1 Score</th>\n",
       "      <th>% Improvement Test Accuracy</th>\n",
       "      <th>% Improvement Test F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vinai/phobert-base-v2</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vinai/phobert-base-v2</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vinai/phobert-base-v2</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ft-rdw-lr2e5-1-ep-bs-64</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>2.045075</td>\n",
       "      <td>1.207535</td>\n",
       "      <td>2.912371</td>\n",
       "      <td>3.043058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ft-rdw-lr2e5-1-ep-bs-64</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>2.867808</td>\n",
       "      <td>5.242545</td>\n",
       "      <td>2.877030</td>\n",
       "      <td>5.528313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ft-rdw-lr2e5-1-ep-bs-64</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>3.841782</td>\n",
       "      <td>3.862156</td>\n",
       "      <td>1.356080</td>\n",
       "      <td>1.385413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ft-wiki-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>4.424040</td>\n",
       "      <td>3.650472</td>\n",
       "      <td>6.314433</td>\n",
       "      <td>6.384492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ft-wiki-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>7.256009</td>\n",
       "      <td>9.734677</td>\n",
       "      <td>7.754060</td>\n",
       "      <td>9.569451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ft-wiki-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>6.342351</td>\n",
       "      <td>6.363526</td>\n",
       "      <td>4.199475</td>\n",
       "      <td>4.225875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vietnamese-eco-Alpaca-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>-0.308848</td>\n",
       "      <td>-1.055444</td>\n",
       "      <td>0.871993</td>\n",
       "      <td>0.767187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Vietnamese-eco-Alpaca-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>2.558267</td>\n",
       "      <td>2.832746</td>\n",
       "      <td>2.997680</td>\n",
       "      <td>3.272096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vietnamese-eco-Alpaca-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>5.546715</td>\n",
       "      <td>5.570507</td>\n",
       "      <td>3.412073</td>\n",
       "      <td>3.427927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ft-wiki-ft-vne-data-similarity-lr2e5-1-ep-bs-48</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>3.021703</td>\n",
       "      <td>1.434750</td>\n",
       "      <td>4.355670</td>\n",
       "      <td>4.329261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ft-wiki-ft-vne-data-similarity-lr2e5-1-ep-bs-48</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>3.814639</td>\n",
       "      <td>7.118585</td>\n",
       "      <td>4.241299</td>\n",
       "      <td>7.403071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ft-wiki-ft-vne-data-similarity-lr2e5-1-ep-bs-48</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>4.819277</td>\n",
       "      <td>4.836121</td>\n",
       "      <td>3.258968</td>\n",
       "      <td>3.278718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ft-vne-ft-wiki-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>5.717863</td>\n",
       "      <td>4.695340</td>\n",
       "      <td>7.542955</td>\n",
       "      <td>7.847099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ft-vne-ft-wiki-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>6.099782</td>\n",
       "      <td>8.582739</td>\n",
       "      <td>6.807425</td>\n",
       "      <td>8.811557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ft-vne-ft-wiki-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>6.842464</td>\n",
       "      <td>6.866518</td>\n",
       "      <td>4.133858</td>\n",
       "      <td>4.164008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vne_wiki_pair_data-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>2.871452</td>\n",
       "      <td>1.160316</td>\n",
       "      <td>3.913230</td>\n",
       "      <td>3.702237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vne_wiki_pair_data-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>5.134741</td>\n",
       "      <td>7.634665</td>\n",
       "      <td>5.206497</td>\n",
       "      <td>7.308710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vne_wiki_pair_data-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>1.864060</td>\n",
       "      <td>1.883751</td>\n",
       "      <td>0.940507</td>\n",
       "      <td>0.968333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vne-ft-eco-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>0.484140</td>\n",
       "      <td>-0.295299</td>\n",
       "      <td>1.198454</td>\n",
       "      <td>1.343742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vne-ft-eco-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>2.931537</td>\n",
       "      <td>3.929231</td>\n",
       "      <td>2.714617</td>\n",
       "      <td>3.962388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vne-ft-eco-rdw-lr2e5-1-ep-bs-48</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>5.023869</td>\n",
       "      <td>5.048330</td>\n",
       "      <td>2.996500</td>\n",
       "      <td>3.021538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ft-eco-vne-data-similarity-rdw-lr2e5-1-ep-bs-64</td>\n",
       "      <td>Vietnamese_Student_Sentiment_Wseg</td>\n",
       "      <td>2.061770</td>\n",
       "      <td>1.018078</td>\n",
       "      <td>2.933849</td>\n",
       "      <td>3.079520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ft-eco-vne-data-similarity-rdw-lr2e5-1-ep-bs-64</td>\n",
       "      <td>Vietnamese_Student_Topic_Wseg</td>\n",
       "      <td>2.831391</td>\n",
       "      <td>5.649775</td>\n",
       "      <td>2.904872</td>\n",
       "      <td>5.508036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ft-eco-vne-data-similarity-rdw-lr2e5-1-ep-bs-64</td>\n",
       "      <td>VMTEB_ViOCD_Wseg</td>\n",
       "      <td>4.387361</td>\n",
       "      <td>4.413404</td>\n",
       "      <td>2.602800</td>\n",
       "      <td>2.634683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Model Name  \\\n",
       "0                             vinai/phobert-base-v2   \n",
       "1                             vinai/phobert-base-v2   \n",
       "2                             vinai/phobert-base-v2   \n",
       "3                           ft-rdw-lr2e5-1-ep-bs-64   \n",
       "4                           ft-rdw-lr2e5-1-ep-bs-64   \n",
       "5                           ft-rdw-lr2e5-1-ep-bs-64   \n",
       "6                      ft-wiki-rdw-lr2e5-1-ep-bs-48   \n",
       "7                      ft-wiki-rdw-lr2e5-1-ep-bs-48   \n",
       "8                      ft-wiki-rdw-lr2e5-1-ep-bs-48   \n",
       "9        Vietnamese-eco-Alpaca-rdw-lr2e5-1-ep-bs-48   \n",
       "10       Vietnamese-eco-Alpaca-rdw-lr2e5-1-ep-bs-48   \n",
       "11       Vietnamese-eco-Alpaca-rdw-lr2e5-1-ep-bs-48   \n",
       "12  ft-wiki-ft-vne-data-similarity-lr2e5-1-ep-bs-48   \n",
       "13  ft-wiki-ft-vne-data-similarity-lr2e5-1-ep-bs-48   \n",
       "14  ft-wiki-ft-vne-data-similarity-lr2e5-1-ep-bs-48   \n",
       "15              ft-vne-ft-wiki-rdw-lr2e5-1-ep-bs-48   \n",
       "16              ft-vne-ft-wiki-rdw-lr2e5-1-ep-bs-48   \n",
       "17              ft-vne-ft-wiki-rdw-lr2e5-1-ep-bs-48   \n",
       "18          vne_wiki_pair_data-rdw-lr2e5-1-ep-bs-48   \n",
       "19          vne_wiki_pair_data-rdw-lr2e5-1-ep-bs-48   \n",
       "20          vne_wiki_pair_data-rdw-lr2e5-1-ep-bs-48   \n",
       "21                  vne-ft-eco-rdw-lr2e5-1-ep-bs-48   \n",
       "22                  vne-ft-eco-rdw-lr2e5-1-ep-bs-48   \n",
       "23                  vne-ft-eco-rdw-lr2e5-1-ep-bs-48   \n",
       "24  ft-eco-vne-data-similarity-rdw-lr2e5-1-ep-bs-64   \n",
       "25  ft-eco-vne-data-similarity-rdw-lr2e5-1-ep-bs-64   \n",
       "26  ft-eco-vne-data-similarity-rdw-lr2e5-1-ep-bs-64   \n",
       "\n",
       "                            Task Name  % Improvement Validation Accuracy  \\\n",
       "0   Vietnamese_Student_Sentiment_Wseg                           0.000000   \n",
       "1       Vietnamese_Student_Topic_Wseg                           0.000000   \n",
       "2                    VMTEB_ViOCD_Wseg                           0.000000   \n",
       "3   Vietnamese_Student_Sentiment_Wseg                           2.045075   \n",
       "4       Vietnamese_Student_Topic_Wseg                           2.867808   \n",
       "5                    VMTEB_ViOCD_Wseg                           3.841782   \n",
       "6   Vietnamese_Student_Sentiment_Wseg                           4.424040   \n",
       "7       Vietnamese_Student_Topic_Wseg                           7.256009   \n",
       "8                    VMTEB_ViOCD_Wseg                           6.342351   \n",
       "9   Vietnamese_Student_Sentiment_Wseg                          -0.308848   \n",
       "10      Vietnamese_Student_Topic_Wseg                           2.558267   \n",
       "11                   VMTEB_ViOCD_Wseg                           5.546715   \n",
       "12  Vietnamese_Student_Sentiment_Wseg                           3.021703   \n",
       "13      Vietnamese_Student_Topic_Wseg                           3.814639   \n",
       "14                   VMTEB_ViOCD_Wseg                           4.819277   \n",
       "15  Vietnamese_Student_Sentiment_Wseg                           5.717863   \n",
       "16      Vietnamese_Student_Topic_Wseg                           6.099782   \n",
       "17                   VMTEB_ViOCD_Wseg                           6.842464   \n",
       "18  Vietnamese_Student_Sentiment_Wseg                           2.871452   \n",
       "19      Vietnamese_Student_Topic_Wseg                           5.134741   \n",
       "20                   VMTEB_ViOCD_Wseg                           1.864060   \n",
       "21  Vietnamese_Student_Sentiment_Wseg                           0.484140   \n",
       "22      Vietnamese_Student_Topic_Wseg                           2.931537   \n",
       "23                   VMTEB_ViOCD_Wseg                           5.023869   \n",
       "24  Vietnamese_Student_Sentiment_Wseg                           2.061770   \n",
       "25      Vietnamese_Student_Topic_Wseg                           2.831391   \n",
       "26                   VMTEB_ViOCD_Wseg                           4.387361   \n",
       "\n",
       "    % Improvement Validation F1 Score  % Improvement Test Accuracy  \\\n",
       "0                            0.000000                     0.000000   \n",
       "1                            0.000000                     0.000000   \n",
       "2                            0.000000                     0.000000   \n",
       "3                            1.207535                     2.912371   \n",
       "4                            5.242545                     2.877030   \n",
       "5                            3.862156                     1.356080   \n",
       "6                            3.650472                     6.314433   \n",
       "7                            9.734677                     7.754060   \n",
       "8                            6.363526                     4.199475   \n",
       "9                           -1.055444                     0.871993   \n",
       "10                           2.832746                     2.997680   \n",
       "11                           5.570507                     3.412073   \n",
       "12                           1.434750                     4.355670   \n",
       "13                           7.118585                     4.241299   \n",
       "14                           4.836121                     3.258968   \n",
       "15                           4.695340                     7.542955   \n",
       "16                           8.582739                     6.807425   \n",
       "17                           6.866518                     4.133858   \n",
       "18                           1.160316                     3.913230   \n",
       "19                           7.634665                     5.206497   \n",
       "20                           1.883751                     0.940507   \n",
       "21                          -0.295299                     1.198454   \n",
       "22                           3.929231                     2.714617   \n",
       "23                           5.048330                     2.996500   \n",
       "24                           1.018078                     2.933849   \n",
       "25                           5.649775                     2.904872   \n",
       "26                           4.413404                     2.602800   \n",
       "\n",
       "    % Improvement Test F1 Score  \n",
       "0                      0.000000  \n",
       "1                      0.000000  \n",
       "2                      0.000000  \n",
       "3                      3.043058  \n",
       "4                      5.528313  \n",
       "5                      1.385413  \n",
       "6                      6.384492  \n",
       "7                      9.569451  \n",
       "8                      4.225875  \n",
       "9                      0.767187  \n",
       "10                     3.272096  \n",
       "11                     3.427927  \n",
       "12                     4.329261  \n",
       "13                     7.403071  \n",
       "14                     3.278718  \n",
       "15                     7.847099  \n",
       "16                     8.811557  \n",
       "17                     4.164008  \n",
       "18                     3.702237  \n",
       "19                     7.308710  \n",
       "20                     0.968333  \n",
       "21                     1.343742  \n",
       "22                     3.962388  \n",
       "23                     3.021538  \n",
       "24                     3.079520  \n",
       "25                     5.508036  \n",
       "26                     2.634683  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_improve.to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "processdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
